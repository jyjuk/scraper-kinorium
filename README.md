<p align="center">
  <img src="assets/1.png" alt="Swagger UI" width="700"/>
</p>

---

## üé• Demo Video
[‚ñ∂Ô∏è –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –¥–µ–º–æ](assets/28.01.2026_21.00.44_REC.mp4)

---

## üì∏ Screenshots

<p align="center">
  <img src="assets/2.png" alt="API Docs" width="600"/>
</p>

<p align="center">
  <img src="assets/3.png" alt="Demo Request" width="600"/>
</p>

<p align="center">
  <img src="assets/34.png" alt="Response Example" width="600"/>
</p>

<p align="center">
  <img src="assets/4.png" alt="Response Example" width="600"/>
</p>

<p align="center">
  <img src="assets/5.png" alt="Another Example" width="600"/>
</p>

<p align="center">
  <img src="assets/6.png" alt="Final Screenshot" width="600"/>
</p>

# Kinorium Scraper API

Asynchronous REST API service for scraping film information from [ua.kinorium.com](https://ua.kinorium.com) using FastAPI, Playwright, and SQLAlchemy.

## Features

- **Three scraping methods**:
  1. HTTP-based scraping (fast, no browser overhead)
  2. Headless browser scraping (Playwright - comprehensive data)
  3. Non-headless browser mode (visible window for debugging)

- **Async architecture** - Built with FastAPI and async/await for high performance
- **Database integration** - SQLAlchemy with async support (SQLite/PostgreSQL)
- **Data validation** - Pydantic schemas for request/response validation
- **Docker support** - Ready-to-deploy containerized application
- **API documentation** - Auto-generated OpenAPI/Swagger docs

## Tech Stack

- **Python 3.11+**
- **FastAPI** - Modern async web framework
- **Playwright** - Browser automation library
- **SQLAlchemy** - Async ORM with aiosqlite
- **Pydantic** - Data validation
- **BeautifulSoup4** - HTML parsing
- **httpx** - Async HTTP client

## Project Structure

```
Scraper/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py           # Configuration management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ genres.py           # Genre mappings
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py         # Database setup
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py           # SQLAlchemy models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ schemas.py          # Pydantic schemas
‚îÇ   ‚îú‚îÄ‚îÄ routers/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scraper.py          # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ improved_scraper.py # Scraping logic
‚îÇ   ‚îî‚îÄ‚îÄ crud/
‚îÇ       ‚îî‚îÄ‚îÄ scraping_results.py # Database operations
‚îú‚îÄ‚îÄ .env.example                # Environment variables template
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ run.py                      # Local server startup script
```

## Quick Start

### Option 1: Docker (Recommended)

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Scraper
   ```

2. **Create environment file**
   ```bash
   cp .env.example .env
   ```

3. **Start with Docker Compose**
   ```bash
   docker-compose up --build
   ```

4. **Access the API**
   - API: http://localhost:8000
   - Documentation: http://localhost:8000/docs

**Note**: The non-headless browser endpoint (#3) is disabled in Docker as it requires GUI.

### Option 2: Local Development

1. **Clone and setup environment**
   ```bash
   git clone <repository-url>
   cd Scraper
   cp .env.example .env
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   playwright install chromium
   ```

4. **Run the server**
   ```bash
   python run.py
   ```

   **Windows users**: The `run.py` script includes Windows-specific event loop configuration required for Playwright. Auto-reload is disabled on Windows for compatibility.

5. **Access the API**
   - API: http://localhost:8000
   - Documentation: http://localhost:8000/docs

## API Endpoints

### 1. Scrape Films by Genre

Scrape films using HTTP requests (no browser automation).

**Endpoint:** `GET /api/v1/scrape/genre`

**Parameters:**
- `genre` (string, required) - Genre name in Ukrainian (e.g., "–∫–æ–º–µ–¥—ñ—è", "–¥—Ä–∞–º–∞", "—Ç—Ä–∏–ª–µ—Ä")

**Example:**
```bash
curl "http://localhost:8000/api/v1/scrape/genre?genre=–∫–æ–º–µ–¥—ñ—è"
```

**Response:**
```json
{
  "genre": "–∫–æ–º–µ–¥—ñ—è",
  "films": [
    {
      "title": "Film Title",
      "url": "https://ua.kinorium.com/12345/"
    }
  ],
  "count": 50
}
```

### 2. Get Film Details

Scrape detailed film information using headless browser.

**Endpoint:** `GET /api/v1/scrape/film/details`

**Parameters:**
- `film_name` (string, required) - Film name to search (in Ukrainian)

**Example:**
```bash
curl "http://localhost:8000/api/v1/scrape/film/details?film_name=–õ–µ–æ–Ω"
```

**Response:**
```json
{
  "film": {
    "title": "–õ–µ–æ–Ω",
    "url": "https://ua.kinorium.com/100515/",
    "year": 1994,
    "rating": 8.5,
    "genres": "–¢—Ä–∏–ª–µ—Ä, –î—Ä–∞–º–∞, –ö—Ä–∏–º—ñ–Ω–∞–ª",
    "director": "–õ—é–∫ –ë–µ—Å—Å–æ–Ω",
    "actors": "–ñ–∞–Ω –†–µ–Ω–æ, –ù–∞—Ç–∞–ª—ñ –ü–æ—Ä—Ç–º–∞–Ω, “ê–µ—Ä—ñ –û–ª–¥–º–∞–Ω",
    "country": "–§—Ä–∞–Ω—Ü—ñ—è, –°–®–ê",
    "duration": "110 —Ö–≤",
    "description": "Professional assassin Leon...",
    "poster_url": "https://..."
  },
  "scraped_at": "2026-01-28T...",
  "scraping_method": "headless"
}
```

### 3. Open in Browser (Local Only)

Open film page in visible browser window (non-headless mode).

**Endpoint:** `GET /api/v1/scrape/film/open-browser`

**Parameters:**
- `film_name` (string, required) - Film name to search

**Example:**
```bash
curl "http://localhost:8000/api/v1/scrape/film/open-browser?film_name=–õ–µ–æ–Ω"
```

**Note:** This endpoint only works in local environment with GUI. Returns 501 error in Docker.

### 4. Get Scraping History

Retrieve previously scraped results from database.

**Endpoint:** `GET /api/v1/results`

**Parameters:**
- `skip` (integer, optional) - Number of records to skip (default: 0)
- `limit` (integer, optional) - Maximum records to return (default: 10, max: 100)

## Configuration

All configuration is managed through environment variables in `.env` file:

```env
# Application settings
APP_NAME=Kinorium Scraper API
DEBUG=True
HOST=0.0.0.0
PORT=8000

# Database settings
DATABASE_URL=sqlite+aiosqlite:///./scraper.db

# Scraping settings
REQUEST_TIMEOUT=30
BROWSER_TIMEOUT=60000
HEADLESS_MODE=True

# Target website
BASE_URL=https://ua.kinorium.com
```

## Database

The application uses SQLite by default. To use PostgreSQL:

1. Update `DATABASE_URL` in `.env`:
   ```env
   DATABASE_URL=postgresql+asyncpg://user:password@localhost/dbname
   ```

2. Install asyncpg:
   ```bash
   pip install asyncpg
   ```

## Development

### Running Tests

The project uses manual testing scripts. To test all endpoints:

```bash
# Test endpoint 1 (Genre)
curl "http://localhost:8000/api/v1/scrape/genre?genre=–∫–æ–º–µ–¥—ñ—è"

# Test endpoint 2 (Details)
curl "http://localhost:8000/api/v1/scrape/film/details?film_name=–¢–∏—Ç–∞–Ω—ñ–∫"

# Test endpoint 3 (Browser - local only)
curl "http://localhost:8000/api/v1/scrape/film/open-browser?film_name=–õ–µ–æ–Ω"
```

### Code Style

- All code comments are in English
- Search supports Ukrainian language
- Follow PEP 8 style guidelines
- Use type hints for all functions

## Important Notes

### Windows Compatibility

When running locally on Windows, the server uses a special startup script (`run.py`) that:
- Sets the Windows event loop policy for Playwright compatibility
- Disables auto-reload mode (required for subprocess support)
- Configures asyncio loop explicitly

**To apply code changes on Windows**: Manually restart the server.

### Docker Limitations

- The non-headless browser endpoint (#3) is disabled in Docker
- This is expected behavior as Docker containers don't have GUI
- Use endpoints #1 and #2 in Docker environment

## License

This project is for educational purposes only.

## Support

For issues and questions, please open an issue on GitHub.

---

**Built with using FastAPI and Playwright**
